{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monkeypox Image Classification Using Transfer Learning\n",
    "\n",
    "This notebook demonstrates how to classify images as \"Monkeypox\" or \"Non Monkeypox\" using transfer learning with popular deep learning models (ResNet50, VGG16, and MobileNetV2). The workflow includes data preparation, model training, evaluation, and saving the trained models for future use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation and Splitting\n",
    "\n",
    "Setting up the dataset structure and splitting data into train, validation, and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2052 images belonging to 2 classes.\n",
      "Found 684 images belonging to 2 classes.\n",
      "Found 684 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import shutil\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Paths to the source folders\n",
    "src_folders = ['dataset/Augmented Images', 'dataset/Original Images']\n",
    "\n",
    "# Paths to the destination folders\n",
    "train_folder = 'dataset/train_data'\n",
    "validation_folder = 'dataset/validation_data'\n",
    "test_folder = 'dataset/test_data'\n",
    "\n",
    "# Create necessary directories\n",
    "for folder in [train_folder, validation_folder, test_folder]:\n",
    "    for label in ['Monkeypox', 'Non Monkeypox']:\n",
    "        os.makedirs(os.path.join(folder, label), exist_ok=True)\n",
    "\n",
    "# Combine data and split into train, validation, and test sets\n",
    "def split_data(src_folders, train_folder, validation_folder, test_folder):\n",
    "    for label in ['Monkeypox', 'Non Monkeypox']:\n",
    "        all_files = []\n",
    "        for folder in src_folders:\n",
    "            src_dir = os.path.join(folder, label)\n",
    "            files = [os.path.join(src_dir, file_name) for file_name in os.listdir(src_dir)]\n",
    "            all_files.extend(files)\n",
    "        \n",
    "        train_files, test_files = train_test_split(all_files, test_size=0.2, random_state=42)\n",
    "        train_files, val_files = train_test_split(train_files, test_size=0.25, random_state=42)  # 20% of the original dataset for validation\n",
    "        \n",
    "        for file_path in train_files:\n",
    "            shutil.copy(file_path, os.path.join(train_folder, label))\n",
    "        \n",
    "        for file_path in val_files:\n",
    "            shutil.copy(file_path, os.path.join(validation_folder, label))\n",
    "        \n",
    "        for file_path in test_files:\n",
    "            shutil.copy(file_path, os.path.join(test_folder, label))\n",
    "\n",
    "# Split the data\n",
    "split_data(src_folders, train_folder, validation_folder, test_folder)\n",
    "\n",
    "# Load data for training, validation, and testing\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_folder,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='binary')\n",
    "\n",
    "validation_generator = test_val_datagen.flow_from_directory(\n",
    "    validation_folder,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='binary')\n",
    "\n",
    "test_generator = test_val_datagen.flow_from_directory(\n",
    "    test_folder,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='binary')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture Setup\n",
    "\n",
    "Creating transfer learning models using pre-trained architectures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet50 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Python311\\Lib\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:979: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94765736/94765736 [==============================] - 20s 0us/step\n",
      "WARNING:tensorflow:From c:\\Python311\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ResNet50\n",
    "\n",
    "def create_resnet_model():\n",
    "    base_model = tf.keras.applications.ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "    base_model.trainable = False\n",
    "    \n",
    "    model = tf.keras.Sequential([\n",
    "        base_model,\n",
    "        tf.keras.layers.GlobalAveragePooling2D(),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "resnet_model = create_resnet_model()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG16 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58889256/58889256 [==============================] - 7s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# VGG16\n",
    "\n",
    "def create_vgg16_model():\n",
    "    base_model = tf.keras.applications.VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "    base_model.trainable = False\n",
    "    \n",
    "    model = tf.keras.Sequential([\n",
    "        base_model,\n",
    "        tf.keras.layers.GlobalAveragePooling2D(),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "vgg16_model = create_vgg16_model()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MobileNetV2 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MobileNetV2\n",
    "\n",
    "def create_mobilenetv2_model():\n",
    "    base_model = tf.keras.applications.MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "    base_model.trainable = False\n",
    "    \n",
    "    model = tf.keras.Sequential([\n",
    "        base_model,\n",
    "        tf.keras.layers.GlobalAveragePooling2D(),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "mobilenetv2_model = create_mobilenetv2_model()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "\n",
    "Training each model for 10 epochs using the prepared data generators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:From c:\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Python311\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "65/65 [==============================] - 137s 2s/step - loss: 0.7195 - accuracy: 0.5439 - val_loss: 0.6825 - val_accuracy: 0.5570\n",
      "Epoch 2/10\n",
      "65/65 [==============================] - 127s 2s/step - loss: 0.6792 - accuracy: 0.5741 - val_loss: 0.6716 - val_accuracy: 0.6140\n",
      "Epoch 3/10\n",
      "65/65 [==============================] - 128s 2s/step - loss: 0.6704 - accuracy: 0.6058 - val_loss: 0.6620 - val_accuracy: 0.6140\n",
      "Epoch 4/10\n",
      "65/65 [==============================] - 124s 2s/step - loss: 0.6591 - accuracy: 0.6316 - val_loss: 0.6531 - val_accuracy: 0.6623\n",
      "Epoch 5/10\n",
      "65/65 [==============================] - 123s 2s/step - loss: 0.6574 - accuracy: 0.6189 - val_loss: 0.6496 - val_accuracy: 0.6754\n",
      "Epoch 6/10\n",
      "65/65 [==============================] - 124s 2s/step - loss: 0.6498 - accuracy: 0.6194 - val_loss: 0.6481 - val_accuracy: 0.6769\n",
      "Epoch 7/10\n",
      "65/65 [==============================] - 124s 2s/step - loss: 0.6443 - accuracy: 0.6506 - val_loss: 0.6431 - val_accuracy: 0.6272\n",
      "Epoch 8/10\n",
      "65/65 [==============================] - 124s 2s/step - loss: 0.6385 - accuracy: 0.6423 - val_loss: 0.6463 - val_accuracy: 0.6433\n",
      "Epoch 9/10\n",
      "65/65 [==============================] - 126s 2s/step - loss: 0.6301 - accuracy: 0.6652 - val_loss: 0.6306 - val_accuracy: 0.6813\n",
      "Epoch 10/10\n",
      "65/65 [==============================] - 125s 2s/step - loss: 0.6265 - accuracy: 0.6706 - val_loss: 0.6207 - val_accuracy: 0.6667\n"
     ]
    }
   ],
   "source": [
    "#Train ResNet50\n",
    "\n",
    "resnet_history = resnet_model.fit(\n",
    "    train_generator, epochs=10, validation_data=validation_generator\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "65/65 [==============================] - 330s 5s/step - loss: 0.6737 - accuracy: 0.6092 - val_loss: 0.6509 - val_accuracy: 0.6681\n",
      "Epoch 2/10\n",
      "65/65 [==============================] - 333s 5s/step - loss: 0.6366 - accuracy: 0.6735 - val_loss: 0.6271 - val_accuracy: 0.6798\n",
      "Epoch 3/10\n",
      "65/65 [==============================] - 331s 5s/step - loss: 0.6172 - accuracy: 0.6798 - val_loss: 0.6139 - val_accuracy: 0.6871\n",
      "Epoch 4/10\n",
      "65/65 [==============================] - 330s 5s/step - loss: 0.6058 - accuracy: 0.6813 - val_loss: 0.6048 - val_accuracy: 0.6813\n",
      "Epoch 5/10\n",
      "65/65 [==============================] - 341s 5s/step - loss: 0.5980 - accuracy: 0.6949 - val_loss: 0.5958 - val_accuracy: 0.6944\n",
      "Epoch 6/10\n",
      "65/65 [==============================] - 357s 5s/step - loss: 0.5906 - accuracy: 0.6964 - val_loss: 0.5884 - val_accuracy: 0.7003\n",
      "Epoch 7/10\n",
      "65/65 [==============================] - 333s 5s/step - loss: 0.5839 - accuracy: 0.7003 - val_loss: 0.5845 - val_accuracy: 0.6974\n",
      "Epoch 8/10\n",
      "65/65 [==============================] - 334s 5s/step - loss: 0.5779 - accuracy: 0.7066 - val_loss: 0.5746 - val_accuracy: 0.7164\n",
      "Epoch 9/10\n",
      "65/65 [==============================] - 330s 5s/step - loss: 0.5715 - accuracy: 0.7125 - val_loss: 0.5717 - val_accuracy: 0.7061\n",
      "Epoch 10/10\n",
      "65/65 [==============================] - 332s 5s/step - loss: 0.5646 - accuracy: 0.7198 - val_loss: 0.5628 - val_accuracy: 0.7208\n"
     ]
    }
   ],
   "source": [
    "#Train VGG16\n",
    "\n",
    "vgg16_history = vgg16_model.fit(\n",
    "    train_generator, epochs=10, validation_data=validation_generator\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "65/65 [==============================] - 31s 438ms/step - loss: 0.5704 - accuracy: 0.6920 - val_loss: 0.4401 - val_accuracy: 0.8202\n",
      "Epoch 2/10\n",
      "65/65 [==============================] - 28s 427ms/step - loss: 0.4151 - accuracy: 0.8265 - val_loss: 0.3817 - val_accuracy: 0.8523\n",
      "Epoch 3/10\n",
      "65/65 [==============================] - 28s 431ms/step - loss: 0.3605 - accuracy: 0.8548 - val_loss: 0.3601 - val_accuracy: 0.8421\n",
      "Epoch 4/10\n",
      "65/65 [==============================] - 28s 425ms/step - loss: 0.3272 - accuracy: 0.8748 - val_loss: 0.3251 - val_accuracy: 0.8874\n",
      "Epoch 5/10\n",
      "65/65 [==============================] - 28s 431ms/step - loss: 0.2971 - accuracy: 0.8933 - val_loss: 0.3134 - val_accuracy: 0.8889\n",
      "Epoch 6/10\n",
      "65/65 [==============================] - 28s 428ms/step - loss: 0.2770 - accuracy: 0.9030 - val_loss: 0.3032 - val_accuracy: 0.8830\n",
      "Epoch 7/10\n",
      "65/65 [==============================] - 28s 429ms/step - loss: 0.2631 - accuracy: 0.9055 - val_loss: 0.2895 - val_accuracy: 0.8977\n",
      "Epoch 8/10\n",
      "65/65 [==============================] - 28s 432ms/step - loss: 0.2444 - accuracy: 0.9191 - val_loss: 0.2757 - val_accuracy: 0.9064\n",
      "Epoch 9/10\n",
      "65/65 [==============================] - 28s 429ms/step - loss: 0.2329 - accuracy: 0.9225 - val_loss: 0.2696 - val_accuracy: 0.9079\n",
      "Epoch 10/10\n",
      "65/65 [==============================] - 28s 428ms/step - loss: 0.2236 - accuracy: 0.9264 - val_loss: 0.2650 - val_accuracy: 0.9094\n"
     ]
    }
   ],
   "source": [
    "#Train MobileNetV2\n",
    "\n",
    "mobilenetv2_history = mobilenetv2_model.fit(\n",
    "    train_generator, epochs=10, validation_data=validation_generator\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Saving\n",
    "\n",
    "Saving the trained models for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "resnet_model.save('resnet50_monkeypox_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16_model.save('vgg16_monkeypox_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobilenetv2_model.save('mobilenetv2_monkeypox_model.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "\n",
    "Evaluating model performance on validation and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 31s 1s/step - loss: 0.6203 - accuracy: 0.6754\n",
      "22/22 [==============================] - 84s 4s/step - loss: 0.5678 - accuracy: 0.7091\n",
      "22/22 [==============================] - 8s 350ms/step - loss: 0.2487 - accuracy: 0.9137\n",
      "ResNet50 Test accuracy: 0.68\n",
      "VGG16 Test accuracy: 0.71\n",
      "MobileNetV2 Test accuracy: 0.91\n"
     ]
    }
   ],
   "source": [
    "# Evaluate each model on the test data\n",
    "resnet_test_loss, resnet_test_acc = resnet_model.evaluate(test_generator)\n",
    "vgg16_test_loss, vgg16_test_acc = vgg16_model.evaluate(test_generator)\n",
    "mobilenetv2_test_loss, mobilenetv2_test_acc = mobilenetv2_model.evaluate(test_generator)\n",
    "\n",
    "print(f'ResNet50 Test accuracy: {resnet_test_acc:.2f}')\n",
    "print(f'VGG16 Test accuracy: {vgg16_test_acc:.2f}')\n",
    "print(f'MobileNetV2 Test accuracy: {mobilenetv2_test_acc:.2f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
